# 提示词语义推荐系统设计方案

## 一、需求分析

### 核心功能
**基于用户输入的提示词，推荐语义相近的候选提示词列表。**

### 核心要求
1. **语义搜索**：基于语义相似度的提示词近似搜索
2. **中英文混合**：支持中文、英文及混合文本
3. **浏览器兼容**：必须在浏览器/Chrome 插件环境运行
4. **轻量级**：体积小、加载快、运行消耗低

### 设计决策
| 决策项 | 选择 | 说明 |
|--------|------|------|
| 分词方案 | jieba-wasm | 支持中英文混合，效果更好 |
| 向量维度 | 256 维 | 平衡精度与存储 |
| Transformers.js | 不使用 | 保持轻量 |
| 分类功能 | 暂不实现 | 先专注于近似推荐 |

### 约束条件
- 运行环境：Chrome 插件 + 浏览器
- 可接受的权衡：准确性 < 性能和体积
- 数据特点：短文本提示词（通常 < 500 字符）

---

## 二、系统架构

### 整体架构图

```
┌─────────────────────────────────────────────────────────────┐
│                    离线处理（构建时/首次加载）                   │
├─────────────────────────────────────────────────────────────┤
│  提示词库  ──→  jieba 分词  ──→  TF-IDF 向量  ──→  IndexedDB   │
│                     ↓                                       │
│              构建词汇表 & IDF 值                              │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                    运行时（浏览器）                            │
├─────────────────────────────────────────────────────────────┤
│  用户输入  ──→  jieba 分词  ──→  TF-IDF 向量  ──→  余弦相似度   │
│                                                ↓            │
│                                          Top-K 推荐结果      │
└─────────────────────────────────────────────────────────────┘
```

### 技术栈

| 层级 | 技术选择 | 说明 |
|------|----------|------|
| 分词 | jieba-wasm | 中英文混合分词，~300KB |
| 向量化 | TF-IDF | 256 维特征向量 |
| 相似度 | 余弦相似度 | 原生 JS 实现 |
| 存储 | IndexedDB | 持久化向量和词汇表 |
| 状态 | Zustand | 与现有架构一致 |

---

## 三、模块设计

### 3.1 目录结构

```
fab-demo/src/
├── service/
│   └── SemanticSearch/
│       ├── index.ts                    # 模块导出
│       ├── SemanticSearchService.ts    # 核心服务类（单例）
│       ├── TextTokenizer.ts            # 文本分词器（jieba-wasm）
│       ├── VectorBuilder.ts            # TF-IDF 向量构建
│       ├── SimilarityCalculator.ts     # 相似度计算
│       ├── SemanticDB.ts               # IndexedDB 存储封装
│       ├── types.ts                    # 类型定义
│       └── constants.ts                # 常量配置
└── stores/
    └── useSemanticSearchStore.ts       # 搜索状态管理（可选）
```

### 3.2 类型定义

```typescript
// types.ts

/**
 * 提示词向量数据
 */
export interface PromptVector {
  id: string;                 // 提示词 ID
  text: string;               // 原始文本（description）
  vector: Float32Array;       // 256 维 TF-IDF 向量
  keywords: string[];         // 提取的关键词（用于展示匹配原因）
  updatedAt: number;          // 最后更新时间戳
}

/**
 * 搜索结果
 */
export interface SearchResult {
  id: string;                 // 提示词 ID
  score: number;              // 相似度分数 (0-1)
  matchedKeywords: string[];  // 匹配的关键词
}

/**
 * 搜索配置选项
 */
export interface SearchOptions {
  topK?: number;              // 返回前 K 个结果，默认 10
  threshold?: number;         // 相似度阈值，默认 0.1
}

/**
 * 词汇表条目
 */
export interface VocabularyEntry {
  word: string;               // 词元
  index: number;              // 在向量中的索引位置
  idf: number;                // IDF 值
  docFreq: number;            // 文档频率
}

/**
 * 服务初始化状态
 */
export type ServiceStatus = 'idle' | 'loading' | 'ready' | 'error';
```

### 3.3 常量配置

```typescript
// constants.ts

export const VECTOR_DIM = 256;              // 向量维度
export const DEFAULT_TOP_K = 10;            // 默认返回数量
export const DEFAULT_THRESHOLD = 0.1;       // 默认相似度阈值
export const MAX_KEYWORDS = 10;             // 最多保存的关键词数

// IndexedDB 配置
export const DB_NAME = 'semantic-search-db';
export const DB_VERSION = 1;
export const STORE_VECTORS = 'vectors';
export const STORE_VOCABULARY = 'vocabulary';
export const STORE_META = 'meta';

// 停用词（中英文）
export const STOP_WORDS = new Set([
  // 中文停用词
  '的', '是', '在', '和', '了', '有', '我', '你', '他', '她', '它',
  '这', '那', '什么', '怎么', '如何', '为什么', '可以', '能够',
  '一个', '一些', '所有', '每个', '任何', '某个',
  // 英文停用词
  'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
  'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
  'could', 'should', 'may', 'might', 'can', 'to', 'of', 'in',
  'for', 'on', 'with', 'at', 'by', 'from', 'as', 'or', 'and',
  'but', 'if', 'then', 'else', 'when', 'where', 'why', 'how',
  'all', 'each', 'every', 'both', 'few', 'more', 'most', 'other',
  'some', 'such', 'no', 'not', 'only', 'same', 'so', 'than', 'too',
  'very', 'just', 'also', 'now', 'here', 'there', 'this', 'that'
]);
```

---

## 四、核心类实现

### 4.1 TextTokenizer - 分词器

```typescript
// TextTokenizer.ts
import * as jieba from 'jieba-wasm';
import { STOP_WORDS } from './constants';

export class TextTokenizer {
  private static instance: TextTokenizer;
  private initialized = false;

  private constructor() {}

  static getInstance(): TextTokenizer {
    if (!TextTokenizer.instance) {
      TextTokenizer.instance = new TextTokenizer();
    }
    return TextTokenizer.instance;
  }

  /**
   * 初始化 jieba-wasm
   */
  async init(): Promise<void> {
    if (this.initialized) return;
    await jieba.init();
    this.initialized = true;
  }

  /**
   * 分词：支持中英文混合
   * @param text 输入文本
   * @returns 词元列表（已去停用词、转小写）
   */
  tokenize(text: string): string[] {
    if (!this.initialized) {
      throw new Error('TextTokenizer not initialized. Call init() first.');
    }

    // 1. jieba 分词
    const tokens = jieba.cut(text, true); // true = 精确模式

    // 2. 清洗：去停用词、转小写、过滤空白
    return tokens
      .map(token => token.toLowerCase().trim())
      .filter(token => 
        token.length > 0 && 
        !STOP_WORDS.has(token) &&
        !/^\s*$/.test(token) &&
        !/^[0-9]+$/.test(token)  // 过滤纯数字
      );
  }

  /**
   * 提取关键词（取词频最高的 N 个）
   */
  extractKeywords(text: string, topN: number = 10): string[] {
    const tokens = this.tokenize(text);
    const freq = new Map<string, number>();
    
    tokens.forEach(t => freq.set(t, (freq.get(t) || 0) + 1));
    
    return [...freq.entries()]
      .sort((a, b) => b[1] - a[1])
      .slice(0, topN)
      .map(([word]) => word);
  }
}
```

### 4.2 VectorBuilder - 向量构建器

```typescript
// VectorBuilder.ts
import { TextTokenizer } from './TextTokenizer';
import { VocabularyEntry, PromptVector } from './types';
import { VECTOR_DIM, MAX_KEYWORDS } from './constants';

export class VectorBuilder {
  private vocabulary: Map<string, VocabularyEntry> = new Map();
  private tokenizer: TextTokenizer;
  private totalDocs = 0;

  constructor() {
    this.tokenizer = TextTokenizer.getInstance();
  }

  /**
   * 从语料库构建词汇表
   * @param corpus 文本列表
   */
  buildVocabulary(corpus: string[]): void {
    const wordDocFreq = new Map<string, number>();
    this.totalDocs = corpus.length;

    // 1. 统计每个词出现在多少文档中
    corpus.forEach(text => {
      const uniqueWords = new Set(this.tokenizer.tokenize(text));
      uniqueWords.forEach(word => {
        wordDocFreq.set(word, (wordDocFreq.get(word) || 0) + 1);
      });
    });

    // 2. 按文档频率排序，取前 VECTOR_DIM 个词
    const sortedWords = [...wordDocFreq.entries()]
      .sort((a, b) => b[1] - a[1])
      .slice(0, VECTOR_DIM);

    // 3. 构建词汇表
    this.vocabulary.clear();
    sortedWords.forEach(([word, docFreq], index) => {
      const idf = Math.log((this.totalDocs + 1) / (docFreq + 1)) + 1;
      this.vocabulary.set(word, { word, index, idf, docFreq });
    });
  }

  /**
   * 将文本转换为 TF-IDF 向量
   */
  textToVector(text: string): Float32Array {
    const tokens = this.tokenizer.tokenize(text);
    const vector = new Float32Array(VECTOR_DIM);
    
    if (tokens.length === 0) return vector;

    // 计算词频
    const termFreq = new Map<string, number>();
    tokens.forEach(t => termFreq.set(t, (termFreq.get(t) || 0) + 1));

    // 计算 TF-IDF
    termFreq.forEach((count, word) => {
      const entry = this.vocabulary.get(word);
      if (entry) {
        const tf = count / tokens.length;
        vector[entry.index] = tf * entry.idf;
      }
    });

    // L2 归一化
    return this.normalize(vector);
  }

  /**
   * 构建提示词向量
   */
  buildPromptVector(id: string, text: string): PromptVector {
    return {
      id,
      text,
      vector: this.textToVector(text),
      keywords: this.tokenizer.extractKeywords(text, MAX_KEYWORDS),
      updatedAt: Date.now()
    };
  }

  /**
   * L2 归一化
   */
  private normalize(vec: Float32Array): Float32Array {
    let sum = 0;
    for (let i = 0; i < vec.length; i++) {
      sum += vec[i] * vec[i];
    }
    const norm = Math.sqrt(sum);
    if (norm > 0) {
      for (let i = 0; i < vec.length; i++) {
        vec[i] /= norm;
      }
    }
    return vec;
  }

  // Getters
  getVocabulary(): Map<string, VocabularyEntry> {
    return this.vocabulary;
  }

  setVocabulary(vocab: Map<string, VocabularyEntry>): void {
    this.vocabulary = vocab;
  }

  getTotalDocs(): number {
    return this.totalDocs;
  }

  setTotalDocs(count: number): void {
    this.totalDocs = count;
  }
}
```

### 4.3 SimilarityCalculator - 相似度计算

```typescript
// SimilarityCalculator.ts
import { PromptVector, SearchResult, SearchOptions } from './types';
import { DEFAULT_TOP_K, DEFAULT_THRESHOLD } from './constants';

export class SimilarityCalculator {
  /**
   * 计算余弦相似度
   * 由于向量已归一化，直接计算点积
   */
  static cosineSimilarity(a: Float32Array, b: Float32Array): number {
    let dot = 0;
    const len = Math.min(a.length, b.length);
    for (let i = 0; i < len; i++) {
      dot += a[i] * b[i];
    }
    return dot;
  }

  /**
   * 查找 Top-K 相似结果
   */
  static findTopK(
    queryVector: Float32Array,
    queryKeywords: string[],
    candidates: PromptVector[],
    options: SearchOptions = {}
  ): SearchResult[] {
    const { topK = DEFAULT_TOP_K, threshold = DEFAULT_THRESHOLD } = options;
    const queryKeywordSet = new Set(queryKeywords);

    const results: SearchResult[] = [];

    for (const candidate of candidates) {
      const score = this.cosineSimilarity(queryVector, candidate.vector);
      
      if (score >= threshold) {
        // 找出匹配的关键词
        const matchedKeywords = candidate.keywords.filter(k => 
          queryKeywordSet.has(k)
        );

        results.push({
          id: candidate.id,
          score,
          matchedKeywords
        });
      }
    }

    // 按分数降序排序，取前 K 个
    return results
      .sort((a, b) => b.score - a.score)
      .slice(0, topK);
  }
}
```

### 4.4 SemanticDB - IndexedDB 存储

```typescript
// SemanticDB.ts
import { PromptVector, VocabularyEntry } from './types';
import { 
  DB_NAME, DB_VERSION, 
  STORE_VECTORS, STORE_VOCABULARY, STORE_META 
} from './constants';

export class SemanticDB {
  private db: IDBDatabase | null = null;

  /**
   * 初始化数据库
   */
  async init(): Promise<void> {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(DB_NAME, DB_VERSION);

      request.onupgradeneeded = () => {
        const db = request.result;
        
        // 向量存储
        if (!db.objectStoreNames.contains(STORE_VECTORS)) {
          db.createObjectStore(STORE_VECTORS, { keyPath: 'id' });
        }
        
        // 词汇表存储
        if (!db.objectStoreNames.contains(STORE_VOCABULARY)) {
          db.createObjectStore(STORE_VOCABULARY, { keyPath: 'word' });
        }
        
        // 元数据存储
        if (!db.objectStoreNames.contains(STORE_META)) {
          db.createObjectStore(STORE_META, { keyPath: 'key' });
        }
      };

      request.onsuccess = () => {
        this.db = request.result;
        resolve();
      };

      request.onerror = () => reject(request.error);
    });
  }

  /**
   * 保存单个向量
   */
  async saveVector(vector: PromptVector): Promise<void> {
    return this.putItem(STORE_VECTORS, {
      ...vector,
      vector: Array.from(vector.vector) // Float32Array -> Array for storage
    });
  }

  /**
   * 批量保存向量
   */
  async saveVectors(vectors: PromptVector[]): Promise<void> {
    const tx = this.db!.transaction(STORE_VECTORS, 'readwrite');
    const store = tx.objectStore(STORE_VECTORS);

    for (const v of vectors) {
      store.put({
        ...v,
        vector: Array.from(v.vector)
      });
    }

    return new Promise((resolve, reject) => {
      tx.oncomplete = () => resolve();
      tx.onerror = () => reject(tx.error);
    });
  }

  /**
   * 加载所有向量
   */
  async loadVectors(): Promise<PromptVector[]> {
    const items = await this.getAllItems<any>(STORE_VECTORS);
    return items.map(item => ({
      ...item,
      vector: new Float32Array(item.vector)
    }));
  }

  /**
   * 删除向量
   */
  async deleteVector(id: string): Promise<void> {
    return this.deleteItem(STORE_VECTORS, id);
  }

  /**
   * 保存词汇表
   */
  async saveVocabulary(vocab: Map<string, VocabularyEntry>): Promise<void> {
    const tx = this.db!.transaction(STORE_VOCABULARY, 'readwrite');
    const store = tx.objectStore(STORE_VOCABULARY);
    
    // 清空旧数据
    store.clear();
    
    // 写入新数据
    vocab.forEach(entry => store.put(entry));

    return new Promise((resolve, reject) => {
      tx.oncomplete = () => resolve();
      tx.onerror = () => reject(tx.error);
    });
  }

  /**
   * 加载词汇表
   */
  async loadVocabulary(): Promise<Map<string, VocabularyEntry>> {
    const items = await this.getAllItems<VocabularyEntry>(STORE_VOCABULARY);
    return new Map(items.map(e => [e.word, e]));
  }

  /**
   * 保存元数据
   */
  async saveMeta(key: string, value: any): Promise<void> {
    return this.putItem(STORE_META, { key, value });
  }

  /**
   * 加载元数据
   */
  async loadMeta(key: string): Promise<any> {
    const item = await this.getItem<{ key: string; value: any }>(STORE_META, key);
    return item?.value;
  }

  // ========== 私有辅助方法 ==========

  private putItem(storeName: string, item: any): Promise<void> {
    return new Promise((resolve, reject) => {
      const tx = this.db!.transaction(storeName, 'readwrite');
      tx.objectStore(storeName).put(item);
      tx.oncomplete = () => resolve();
      tx.onerror = () => reject(tx.error);
    });
  }

  private getItem<T>(storeName: string, key: string): Promise<T | undefined> {
    return new Promise((resolve, reject) => {
      const tx = this.db!.transaction(storeName, 'readonly');
      const request = tx.objectStore(storeName).get(key);
      request.onsuccess = () => resolve(request.result);
      request.onerror = () => reject(request.error);
    });
  }

  private deleteItem(storeName: string, key: string): Promise<void> {
    return new Promise((resolve, reject) => {
      const tx = this.db!.transaction(storeName, 'readwrite');
      tx.objectStore(storeName).delete(key);
      tx.oncomplete = () => resolve();
      tx.onerror = () => reject(tx.error);
    });
  }

  private getAllItems<T>(storeName: string): Promise<T[]> {
    return new Promise((resolve, reject) => {
      const tx = this.db!.transaction(storeName, 'readonly');
      const request = tx.objectStore(storeName).getAll();
      request.onsuccess = () => resolve(request.result);
      request.onerror = () => reject(request.error);
    });
  }
}
```

### 4.5 SemanticSearchService - 核心服务

```typescript
// SemanticSearchService.ts
import { TextTokenizer } from './TextTokenizer';
import { VectorBuilder } from './VectorBuilder';
import { SimilarityCalculator } from './SimilarityCalculator';
import { SemanticDB } from './SemanticDB';
import { 
  PromptVector, SearchResult, SearchOptions, ServiceStatus 
} from './types';

export class SemanticSearchService {
  private static instance: SemanticSearchService;

  private tokenizer: TextTokenizer;
  private vectorBuilder: VectorBuilder;
  private db: SemanticDB;
  private vectors: PromptVector[] = [];
  private status: ServiceStatus = 'idle';

  private constructor() {
    this.tokenizer = TextTokenizer.getInstance();
    this.vectorBuilder = new VectorBuilder();
    this.db = new SemanticDB();
  }

  static getInstance(): SemanticSearchService {
    if (!SemanticSearchService.instance) {
      SemanticSearchService.instance = new SemanticSearchService();
    }
    return SemanticSearchService.instance;
  }

  /**
   * 初始化服务
   */
  async initialize(): Promise<void> {
    if (this.status === 'ready' || this.status === 'loading') return;

    try {
      this.status = 'loading';

      // 1. 初始化分词器
      await this.tokenizer.init();

      // 2. 初始化数据库
      await this.db.init();

      // 3. 加载词汇表
      const vocabulary = await this.db.loadVocabulary();
      if (vocabulary.size > 0) {
        this.vectorBuilder.setVocabulary(vocabulary);
        const totalDocs = await this.db.loadMeta('totalDocs');
        if (totalDocs) this.vectorBuilder.setTotalDocs(totalDocs);
      }

      // 4. 加载已索引的向量
      this.vectors = await this.db.loadVectors();

      this.status = 'ready';
    } catch (error) {
      this.status = 'error';
      throw error;
    }
  }

  /**
   * 获取服务状态
   */
  getStatus(): ServiceStatus {
    return this.status;
  }

  /**
   * 语义搜索
   * @param query 查询文本
   * @param options 搜索选项
   */
  async search(query: string, options?: SearchOptions): Promise<SearchResult[]> {
    this.ensureReady();

    if (!query.trim()) return [];

    // 1. 构建查询向量
    const queryVector = this.vectorBuilder.textToVector(query);
    const queryKeywords = this.tokenizer.extractKeywords(query);

    // 2. 计算相似度并返回 Top-K
    return SimilarityCalculator.findTopK(
      queryVector,
      queryKeywords,
      this.vectors,
      options
    );
  }

  /**
   * 索引单个提示词
   */
  async indexPrompt(id: string, text: string): Promise<void> {
    this.ensureReady();

    const vector = this.vectorBuilder.buildPromptVector(id, text);
    
    // 更新内存
    const existingIndex = this.vectors.findIndex(v => v.id === id);
    if (existingIndex >= 0) {
      this.vectors[existingIndex] = vector;
    } else {
      this.vectors.push(vector);
    }

    // 持久化
    await this.db.saveVector(vector);
  }

  /**
   * 批量索引提示词（用于初始化）
   */
  async indexBatch(prompts: Array<{ id: string; text: string }>): Promise<void> {
    this.ensureReady();

    // 1. 重建词汇表
    const corpus = prompts.map(p => p.text);
    this.vectorBuilder.buildVocabulary(corpus);

    // 2. 向量化所有提示词
    this.vectors = prompts.map(p => 
      this.vectorBuilder.buildPromptVector(p.id, p.text)
    );

    // 3. 持久化
    await this.db.saveVocabulary(this.vectorBuilder.getVocabulary());
    await this.db.saveMeta('totalDocs', this.vectorBuilder.getTotalDocs());
    await this.db.saveVectors(this.vectors);
  }

  /**
   * 删除提示词索引
   */
  async removePrompt(id: string): Promise<void> {
    this.ensureReady();

    this.vectors = this.vectors.filter(v => v.id !== id);
    await this.db.deleteVector(id);
  }

  /**
   * 获取已索引的提示词数量
   */
  getIndexedCount(): number {
    return this.vectors.length;
  }

  /**
   * 清空所有索引
   */
  async clearAll(): Promise<void> {
    this.vectors = [];
    // 清空 IndexedDB（需要实现）
  }

  private ensureReady(): void {
    if (this.status !== 'ready') {
      throw new Error('SemanticSearchService not ready. Call initialize() first.');
    }
  }
}
```

### 4.6 模块导出

```typescript
// index.ts
export { SemanticSearchService } from './SemanticSearchService';
export { TextTokenizer } from './TextTokenizer';
export { VectorBuilder } from './VectorBuilder';
export { SimilarityCalculator } from './SimilarityCalculator';
export { SemanticDB } from './SemanticDB';
export * from './types';
export * from './constants';
```

---

## 五、使用示例

### 5.1 初始化与批量索引

```typescript
import { SemanticSearchService } from '@/service/SemanticSearch';
import { mockPrompts } from '@/data/mockData';

// 获取服务实例
const searchService = SemanticSearchService.getInstance();

// 初始化
await searchService.initialize();

// 批量索引现有提示词
const prompts = mockPrompts.map(p => ({
  id: p.id.toString(),
  text: p.description
}));
await searchService.indexBatch(prompts);

console.log(`Indexed ${searchService.getIndexedCount()} prompts`);
```

### 5.2 搜索推荐

```typescript
// 搜索相似提示词
const results = await searchService.search('React 组件优化', {
  topK: 5,
  threshold: 0.15
});

results.forEach(r => {
  console.log(`ID: ${r.id}, Score: ${r.score.toFixed(3)}, Keywords: ${r.matchedKeywords.join(', ')}`);
});
```

### 5.3 增量索引

```typescript
// 添加新提示词时
await searchService.indexPrompt('new-123', '使用 TypeScript 开发 Vue3 组件');

// 删除提示词时
await searchService.removePrompt('old-456');
```

---

## 六、与现有系统集成

### 6.1 集成到 PromptLibrary

在 `usePromptListStore` 中添加语义搜索支持：

```typescript
// stores/usePromptListStore.ts
import { SemanticSearchService } from '@/service/SemanticSearch';

interface PromptListState {
  // ... 现有状态
  searchMode: 'keyword' | 'semantic';  // 新增：搜索模式
  semanticResults: string[];           // 语义搜索结果 ID 列表
  
  // ... 现有 actions
  setSearchMode: (mode: 'keyword' | 'semantic') => void;
  semanticSearch: (query: string) => Promise<void>;
}
```

### 6.2 UI 集成点

1. **搜索框**：添加切换按钮（关键词搜索 / 语义搜索）
2. **搜索结果**：显示匹配分数和关键词
3. **加载状态**：首次加载时显示初始化进度

---

## 七、性能预估

### 资源占用

| 组件 | 大小 | 说明 |
|------|------|------|
| jieba-wasm | ~300KB | 分词库 |
| 核心代码 | ~10KB | TS 编译后 |
| 词汇表 | ~50KB | 256 词 × 元数据 |
| 向量数据 | ~1.2KB/条 | 256 × Float32 + 元数据 |
| **总计（1000条）** | **~1.6MB** | IndexedDB 存储 |

### 性能指标（预估）

| 操作 | 时间 | 备注 |
|------|------|------|
| jieba 初始化 | 300-500ms | 首次加载 |
| 服务初始化 | <200ms | 加载已有数据 |
| 单次搜索 | <15ms | 1000 条数据 |
| 向量生成 | <5ms | 单条提示词 |
| 批量索引 | ~50ms | 100 条 |

---

## 八、实施计划

### Phase 1：基础架构（1-2天）
- [ ] 创建 `src/service/SemanticSearch/` 目录结构
- [ ] 安装 jieba-wasm 依赖
- [ ] 实现 `TextTokenizer` 分词器
- [ ] 实现 `VectorBuilder` 向量构建
- [ ] 实现 `SimilarityCalculator` 相似度计算

### Phase 2：存储与服务（1-2天）
- [ ] 实现 `SemanticDB` IndexedDB 封装
- [ ] 实现 `SemanticSearchService` 核心服务
- [ ] 添加单元测试

### Phase 3：集成与优化（1天）
- [ ] 集成到 `PromptLibrary` 组件
- [ ] 添加搜索模式切换 UI
- [ ] 性能测试与优化

---

## 九、依赖说明

需要安装的新依赖：

```bash
npm install jieba-wasm
```

jieba-wasm 是 jieba 分词的 WebAssembly 版本，支持浏览器环境，体积约 300KB。

---

**设计方案已更新完成，请审阅！**
